CAPSTONE_PROJECT_SU24

The question bank plays a critical role in educational assessment and undergoes frequent 
updates. As the number of questions in these banks grows, detecting duplicate questions 
becomes essential. Manual verification of duplicates is time-consuming and resource-intensive, 
necessitating an effective and robust solution. To address this challenge, this study proposes a 
ranking system that leverages large language models (LLMs). Our approach considers two key 
aspects: learning outcomes (Los) and learning materials (LMs). The system includes data 
acquisition and preprocessing, ranking mechanisms, prompt engineering, and evaluation 
methods. It allows querying to find similar questions based on similarity ranking. Our approach 
demonstrates promising results compared to traditional methods, deep learning techniques, and 
other LLM-based approaches.